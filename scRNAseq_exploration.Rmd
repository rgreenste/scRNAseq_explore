---
title: "Exploring scRNA-seq Data Processing and Analysis"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
# dependencies generally needed
library(SingleCellExperiment)
library(scater)
library(scran)
library(uwot)
library(Rtsne)
```

## R Markdown



```{r}
## -- reading in the 10x data  -- ##

library(BiocFileCache)
bfc <- BiocFileCache("./raw_data", ask = FALSE)
guiu.zip <- bfcrpath(bfc, 
                    file.path("https://www.ebi.ac.uk/arrayexpress/files",
                              "E-MTAB-7660/E-MTAB-7660.processed.1.zip"))
unzip(guiu.zip, exdir = "./raw_data")
tarPath <- file.path("./raw_data/guiu2019_10xProcessed.tar.gz")
untar(tarPath,exdir = "./raw_data")

```

## Including Plots



```{r}
library(DropletUtils)
library(Matrix)
files <- file.path(getwd(), "./raw_data/guiu2019_10xProcessed/raw_gene_bc_matrices/mm10")
sce.guiu <- read10xCounts(files, col.names=TRUE)
sce.guiu

```

```{r}
# do some exploring of this sce 
dim(sce.guiu)
assays(sce.guiu)

head(rownames(sce.guiu))# confirmed annotation with Ensembl notation

head(rowData(sce.guiu)) # annotated with gene ID and gene Symbol

names(colData(sce.guiu)) # sample names and cell barcode

table(grepl("^ERCC", rownames(sce.guiu))) # there are no ERCC spike ins

table(grepl("^SIRV", rownames(sce.guiu))) # there are no SIRV spike ins

```

```{r}
## -- quality control by removing empty droplets-- ##

barcodeRank <- barcodeRanks(counts(sce.guiu))
# Only showing unique points for plotting speed.
uniqBc <- !duplicated(barcodeRank$rank)
plot(barcodeRank$rank[uniqBc], barcodeRank$total[uniqBc], log="xy",
     xlab="Barcode Rabk", ylab="Total UMI count", cex.lab=1.2)

abline(h=metadata(barcodeRank)$inflection, col="red", lty=2)
abline(h=metadata(barcodeRank)$knee, col="blue", lty=2)

legend("bottomleft", legend=c("Inflection", "Knee"), 
       col=c("red", "blue"), lty=2, cex=1.2)

```


```{r}
# use emptyDrops function to remove empty drops (uses monte carlo sim so have to set.seed)
set.seed(101)

# calculates pValues to determine cell from drops with FDR 0.001
e.out <- emptyDrops(counts(sce.guiu))
summary(e.out$FDR <= 0.001)
# subset the sce based on the columns which pass our FDR cutoff of 0.1%
sce.guiu <- sce.guiu[,which(e.out$FDR <= 0.001)]
dim(sce.guiu) # now there are only 5289 cells remaining

```



```{r}
unfiltered <- sce.guiu # save the sce post removing empty's but before additional QC
```



## Importing Mouse Genome Annotation
```{r}
library(AnnotationHub) # load the ensembldb
ah = AnnotationHub() # create annotation hub object


```


```{r}
#load emsembl db v98 for mouse
dbNumber<-names(query(ah, c('Ensembl', 'musculus', 'EnsDb', '98')))
eDb<-ah[[dbNumber]] 
keytypes(eDb) # remind me what keys are availble to select records with
columns(eDb)
```

```{r}
## Goal - to retrieve the chromosome location of each gene in sce.guiu to see if it is mtDNA
chrom<-mapIds(eDb, keys = rowData(sce.guiu)$ID, column = "SEQNAME", keytype = "GENEID")
# genes belonging to mtDNA as determined from chrom/edb
mito<-which(chrom=="MT")
```

```{r}
# Compute the QC metrics per cell
library(scater)
metrics <- perCellQCMetrics(unfiltered, subsets=list(Mito=mito))
head(metrics)


metrics.lib <- isOutlier(metrics$sum, log=TRUE, nmads = 2, type="lower")
attr(metrics.lib, "thresholds")
metrics.exprs <- isOutlier(metrics$detected, log=TRUE, nmads = 2,type="lower")
attr(metrics.exprs, "thresholds")
metrics.mito <- isOutlier(metrics$subsets_Mito_percent,nmads = 2, type="higher")
attr(metrics.mito, "thresholds")


discard <- metrics.lib | metrics.nexprs | metrics.mito
```

```{r}
# Summarize the number of cells removed by which reason.
DataFrame(libSize=sum(metrics.lib), exprs=sum(metrics.exprs),
           mitoPercent=sum(metrics.mito), total=sum(discard))
```

```{r}
# column bind the states from perCellQC to the original sce now called unfiltered
colData(unfiltered) <- cbind(colData(unfiltered), metrics)
# add a new column called discard that includes the logical for metrics.mito
unfiltered$discard <- discard
```

```{r, echo=FALSE}
# take a look at what the filtering did with plots colored by discard identity
gridExtra::grid.arrange(
  plotColData(unfiltered, y="sum", colour_by="discard") +
    scale_y_log10() + ggtitle("total count"),
  plotColData(unfiltered, y="detected", colour_by="discard") +
    scale_y_log10() + ggtitle("detected features"),
  plotColData(unfiltered, y="subsets_Mito_percent",
    colour_by="discard") + ggtitle("percent mito"),
  ncol=2
)
```

```{r}
#compare filtering metrics to each other
plotColData(unfiltered, x="sum", y="detected",
            colour_by="discard") + scale_x_log10()
plotColData(unfiltered, x="sum", y="subsets_Mito_percent",
            colour_by="discard") + scale_x_log10()

```

```{r}
# Keeping the columns we DON'T want to discard.
filtered <- unfiltered[,!discard]
dim(filtered)
dim(unfiltered)
```

```{r}
## -- normalization by deconvolution (removing composition bias) -- ##

library(scran)
set.seed(100)
clust.guiu <- quickCluster(filtered) # first do quick clustering - cells in each clusterare 
#normalized separately and the size factors are rescaled to be comparable across clusters
table(clust.guiu) # how many clusters and how many cells in each


```

```{r}
lib.sf.guiu <- librarySizeFactors(filtered)
summary(lib.sf.guiu)
hist(log10(lib.sf.guiu), xlab="Log10[Size factor]", col='grey80')
decov.sf.guiu<-calculateSumFactors(filtered, cluster=clust.guiu)
summary(decov.sf.guiu)
hist(log10(decov.sf.guiu), xlab="Log10[Size factor]", col='grey80')

```

```{r}
filtered <- computeSumFactors(filtered, cluster=clust.guiu)
filtered <- logNormCounts(filtered)
summary(sizeFactors(filtered))
assays(filtered) # now there are two assays the counts & the log normalized counts just made

```

```{r}
## -- modeling the variance and selection highly variable genes (HVGs) -- ##

set.seed(101)
filtered.pois <- modelGeneVarByPoisson(filtered)
filtered.pois <- filtered.pois[order(filtered.pois$bio, decreasing=TRUE),]
head(filtered.pois)

top.genes <- getTopHVGs(filtered.pois, prop=0.1) # keeps the top 10% as HGVs
length(top.genes) #1453 genes


```

```{r}
set.seed(101)
filtered.var <- modelGeneVar(filtered)
filtered.var <- filtered.var[order(filtered.var$bio, decreasing=TRUE),]
head(filtered.var)

top.genes.var <- getTopHVGs(filtered.var, prop=0.1) # keeps the top 10% as HGVs
length(top.genes.var) #1240 genes
top.genes.varFDR <- getTopHVGs(filtered.var, fdr.threshold = 0.05) 
length(top.genes.varFDR) #1240 genes

```

